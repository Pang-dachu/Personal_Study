# Chapter3. 합성곱 신경망

## intro
<details>
<summary>Intro</summary>

* 신경망과 MLP는 각각 학습이 가능한 가중치와 편향을 가진 뉴런이 층 모양으로 모여 이루는 구조

* 입력에 가중치를 곱하고 가중치의 합에 편향을 더하며 활성화 함수를 적용, 비선형성을 적용

* 가중치 구조 : 무작위 값으로 초기화 되는 가중치와 편향

</details>

## 3.1 다층 퍼셉트론을 이용한 이미지 분류 
<details>

### 3.1.5 MLP로 이미지를 다룰 때의 단점 

단점 2가지 

1. 2차원 이미지를 1차원 벡터로 변형하면 이미지 내의 공간적 특징이 손실됨
    - 서로 가까이에 위치한 픽셀 간의 관계를 알 수 없게 되어 정보의 손실이 발생
    - 서로 연결되어 있었다는, 근처에 있었다는 정보를 알 수 없게 된다.

2. MLP는 특징으로 이미지를 학습하지 않는다.
    - 학습한 이미지에서 위치나 각도가 조금만 틀어져도 정확도가 낮아진다.


* 합성곱 신경망 구조의 의의
    - 2차원 행렬인 이미지를 1차원 벡터로 변환하면서 손실되는 정보, 전결합층의 계산 복잡도
    - 픽셀값의 특징, 숨어있는 패턴을 이해할 수 있게 된다. 

</details>

## 3.2 합성곱 신경망 구조
<details>

* 첫번째 층에서 기본적인 특징 (모서리, 직선)을 학습
* 다음 층에서는 조금 더 복잡한 (원 , 정사각형) 특징을 학습
* 그 다음 층에서는 더 복잡한 (바퀴, 강아지 수염 등) 특징을 학습

### 3.2.1 전체 학습 과정

* 딥러닝 이전에서는 특징을 사람이 직접 추출

* 이미지 학습시에 FC의 문제는 특징 학습 단계에서 발생
    - FC는 추출된 특징에 대해서는 우수하게 작동

### 3.2.2 특징 추출 과정

* 특성 맵, 특징 추출이란 이미지를 여러 개의 작은 특징 맵으로 나누어 이를 쌓아 벡터로 구조화 하는 것

* 한 층만에 특징이 추출 되는 것이 아닌 층을 거쳐가며 큰 특징부터 세부적인 특징으로 서서히 특징을 추출한다는 느낌 

</details>

## 3.3 합성곱 신경망의 기본 요소 
<details>

* 합성곱이란 : 두 함수를 인수로 새로운 함수를 만들어 내는 연산

* 따라서 "입력 이미지"와 "합성곱 필터"를 인수로 하여 새로운 특징 맵을 생성해 내는 것

* 뉴런, 가중치의 값이 kernel 이라는 것에 행렬처럼 배열되어 있다

* CNN의 은닉층 활성화 함수는 relu를 사용하는 것이 현재는 좋다

* 커널 크기, 스트라이드, 패딩을 적절히 조합해서 사용할 것

* 스트라이드와 패딩의 목적은 이미지의 공간적인 정보를 계산하는 부하를 적절히 감소하기 위함

* 풀링 : 다음 층으로 전달하는 파라미터 갯수를 감소하기 위함 (규모를 줄인다)
    - 특징은 유지하면서 이미지의 해상도를 떨어트리는 과정
    - 풀링에서는 가중치가 없기 때문에 생성되는 파라미터 또한 없다 

</details>