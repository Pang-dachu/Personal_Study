# 수업간의 질문 사항

1. RNN은 가중치를 동일하게 사용한다.
    - 같은 시점에서는 동일한 가중치를 사용한다 (영화 평론 액션성에 예시)
    - 가중치는 하나의 미니배치 단위가 종료된 이후 역전파를 통해 조정됨
    

2. Back Propagation

-순서 

    1. 정방향(feedforward) 계산: 입력 데이터를 입력층(input layer)으로 받아 출력층(output layer)까지 연산을 진행하여 예측값을 출력합니다.

    2. 손실 함수(loss function) 계산: 실제값과 예측값을 비교하여 손실 함수(loss function)를 계산합니다.

    3. 역방향(backward) 계산: 오차 역전파 알고리즘을 사용하여 출력층에서부터 입력층까지 역방향으로 오차를 전파합니다.
    (이 과정에서 각 층의 미분값(gradient)을 구해 가중치 업데이트)

    4. 가중치(weight) 업데이트: 역방향 계산을 기반으로 각 층의 가중치를 업데이트합니다.

    5. 1~4 과정을 반복: 다음 데이터를 입력으로 받아 14 과정을 반복하여 모델을 학습시킵니다.

- 왜 필요한가 ?
    * Backpropagation 알고리즘은 인공 신경망의 깊이(depth)가 깊어질수록, 즉 레이어(layer)의 개수가 많아질수록 학습이 어려워지는 문제를 해결하기 위해 고안되었다.


3. RNN의 활성화 함수

    - RNN 모델에서는 입력 데이터가 시간에 따라 변화하기 때문에, ReLU와 같은 비선형 활성화 함수가 부적합

    - 수렴한다의 정의 ? : 손실 함수 값이 더 이상 줄어들지 않고 일정한 값으로 수렴하는 상태
        1. Relu 함수는 수렴하지 않고, tanh 함수는 수렴한다고 말할 수 있다.

    * Relu
        - Relu 함수는 입력값이 0 이상인 경우에는 선형적으로 값을 전달하고, 입력값이 0 이하인 경우에는 값을 0으로 바꾸어 주는 함수
        - Relu 함수의 장점 중 하나는 그래디언트가 0 이상인 영역에서는 그래디언트 값이 일정하게 유지된다는 점

    * tanh
        - tanh 함수는 입력값이 작아질수록 출력값이 -1로 수렴하고, 입력값이 커질수록 출력값이 1로 수렴
        - tanh 함수는 출력 범위가 제한되어 있기 때문에 수렴한다고 말할 수 있다.
        - tanh 함수는 그래디언트 소실 문제가 발생할 가능성이 높기 때문에, 모델의 깊이가 깊을수록 학습이 어려워질 수 있다.

    * Sigmoid 
        - 출력 값은 0과 1 사이의 값으로 제한
        - 도함수는 최댓값이 0.25 이하, 이렇게 작은 값이 반복적으로 곱해지면 기울기가 급격히 작아져서 그래디언트 소실 문제가 발생


4. RNN에서 같은 시점에 가중치가 달라진다면 ? 

    - 첫째, 시간 축을 따라 RNN 모델이 펼쳐진 구조에서는 이전 시점에서의 출력이 다음 시점에서의 입력으로 사용되기 때문에, 하나의 미니배치 학습에서 현재 시점에서의 가중치가 변경되면 이전 시점까지의 출력에 영향을 미친다. 이러한 상황에서는 이전 시점의 출력과 현재 시점의 출력이 일관성 없이 변경될 수 있어, 모델의 성능이 저하될 수 있다.

    - 둘째, RNN 모델에서는 일반적으로 역전파(backpropagation) 알고리즘을 사용하여 가중치를 학습시킨다. 
    이때, 하나의 미니배치 학습간에 가중치가 너무 크게 변하게 되면, 그래디언트(gradient)가 폭주하거나 소실되는 문제가 발생할 수 있다. 이러한 문제는 모델의 학습을 불안정하게 만들어 수렴하지 않거나, 수렴에 많은 시간이 소요되는 등의 문제를 야기할 수 있다.

    - 따라서, RNN 모델에서는 하나의 미니배치 학습간에 가중치가 크게 변하지 않도록, 일정한 범위 내에서 변화하도록 학습률(learning rate)을 적절하게 설정하고, 가중치 초기화(weight initialization)와 같은 기술들을 사용하여 그래디언트 소실과 폭주 문제를 해결할 필요가 있다. 또한, RNN 모델에서는 각 시점에서의 출력을 다음 시점에서의 입력으로 사용하므로, 이전 시점에서의 출력을 저장하는 상태 셀(state cell) 등의 메모리 기반 모델을 사용하여, 입력과 출력의 일관성을 유지할 수 있도록 해야 한다.